{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a50e956-b4d3-4091-9c87-383f38b6c23f",
   "metadata": {},
   "source": [
    "## Random Forest Regression Model \n",
    "The Random Forest Regressor was selected due to its effectiveness in the regression tasks especially when dealing with complex datasets (level 3), that may have non-linear relationships. This choice was driven beacause of the need for a model that balances accuracy and interpretability.\n",
    "\n",
    "### Steps to Create the Model and Prediction\n",
    "#### Loading the Data: \n",
    "The preprocessed datset was loaded as a dataframe. Various features related to taxi trips were observed. \n",
    "\n",
    "#### Data Preparation:\n",
    "The target variable was dropped from the features(X) and set in Y.Irrelevant columns (i.e.., 'congestion_surcharge','improvement_surcharge','passenger_count','mta_tax','tolls_amount','is_peak_month', 'payment_type_Unknown','RatecodeID_6.0') were dropped from the features (X) to focus on those most relevant for predicting the target variable (fare_amount), 'total_amount' was also dropped because it had high correlation that resulted in overfitting. These features were termed irrelevant based on the model feature importance values. This step ensures that the model trains on features that are likely to influence the outcome.\n",
    "\n",
    "#### Splitting the Data:\n",
    "The dataset was then split into training and testing sets, with 80% of the data used for the training and 20% for testing with random state at 42. This split will allows the model to learn while evaluating it's performance.\n",
    "\n",
    "#### Initializing the Model:\n",
    "Random Forest Regressor was initialized with 100 trees (i.e.., n_estimators=100).\n",
    "Training the Model:\n",
    "\n",
    "\n",
    "#### Making Predictions:\n",
    "Predictions were made on the test set (i.e.., X_test) using the predict() method, which then generated predicted values for target fare_amount.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe97d385-8071-4b98-8d9e-efc47cfe927c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.58\n",
      "Mean Squared Error: 2.03\n",
      "R^2 Score: 0.96\n",
      "Model Accuracy: 0.9607001571394429\n",
      "                          Importance\n",
      "trip_duration               0.806437\n",
      "trip_distance               0.133688\n",
      "VendorID_2                  0.009969\n",
      "DOLocationID                0.009559\n",
      "PULocationID                0.008449\n",
      "pickup_hour                 0.006153\n",
      "tip_amount                  0.006066\n",
      "pickup_dayofyear            0.005376\n",
      "pickup_dayofweek            0.003014\n",
      "RatecodeID_5.0              0.002608\n",
      "payment_type_Credit Card    0.002471\n",
      "pickup_weekofyear           0.002130\n",
      "RatecodeID_2.0              0.001141\n",
      "extra                       0.001112\n",
      "pickup_month                0.000606\n",
      "is_peak_hour                0.000606\n",
      "is_peak_day                 0.000431\n",
      "RatecodeID_4.0              0.000119\n",
      "trip_type_Street-hail       0.000031\n",
      "payment_type_No Charge      0.000026\n",
      "payment_type_Dispute        0.000005\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import pandas as pd\n",
    "\n",
    "file_path = 'raw_tripdata_2022-01.csv'\n",
    "data_cleaned = pd.read_csv(file_path)\n",
    "\n",
    "# Drop the target and also unimportant features\n",
    "unimportant_features = ['congestion_surcharge','improvement_surcharge','passenger_count','mta_tax','tolls_amount','is_peak_month', 'payment_type_Unknown','RatecodeID_6.0']\n",
    "X = data_cleaned.drop(columns=['fare_amount','total_amount'] + unimportant_features)\n",
    "y = data_cleaned['fare_amount']\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Random Forest Regressor\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "accuracy = rf_model.score(X_test, y_test)\n",
    "print(f\"Mean Absolute Error: {mae:.2f}\")\n",
    "print(f\"Mean Squared Error: {mse:.2f}\")\n",
    "print(f\"R^2 Score: {r2:.2f}\")\n",
    "print(f\"Model Accuracy: {accuracy}\")\n",
    "\n",
    "# Feature Importance\n",
    "importances = rf_model.feature_importances_\n",
    "feature_importances = pd.DataFrame(importances, index=X.columns, columns=[\"Importance\"]).sort_values(\"Importance\", ascending=False)\n",
    "print(feature_importances)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f310050-3716-419b-a948-5011e066b42c",
   "metadata": {},
   "source": [
    "### Model Performance:\n",
    "##### Mean Absolute Error (MAE): 0.58\n",
    "##### Mean Squared Error (MSE): 2.03\n",
    "##### R² Score: 0.96\n",
    "##### Model Accuracy: 0.9607\n",
    "##### Feature Importance: \n",
    "The importance of each feature provided insight into which features contribute most to the predictions. Therefore features with low(>0.000005) values that were termed insignificant and dropped.\n",
    "\n",
    "### Is the Model a Good Model? \n",
    "Yes, the model seems to be a good for several reasons as its R² score of 0.96 is indicative of strong relationship between the features and the target variable i.e.., the model captures almost all of the variance.\n",
    "The Mean Absolute Error (MAE) of 0.58 shows that the model's prediction error is relatively low i.e.. it is indicating accurate predictions in real-world terms (i.e.., fare amounts).\n",
    "\n",
    "#### Feature Selection:\n",
    "Specific features (i.e.., 'congestion_surcharge','improvement_surcharge','passenger_count','mta_tax','tolls_amount','is_peak_month', 'payment_type_Unknown','RatecodeID_6.0') were deliberately dropped from the dataset to improve model performance and interpretability. To do this the model was built repeatedly and the importance values were considered, where in every built one of the low valued features were removed, this continued until the best scores were obtained and hence, that is the final model.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
